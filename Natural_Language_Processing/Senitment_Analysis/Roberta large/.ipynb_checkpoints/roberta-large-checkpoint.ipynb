{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters:  355412057\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Importing the tokenizer and model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"roberta-large\")\n",
    "\n",
    "# Model parameters.\n",
    "param = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total Parameters: \", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_ids: tensor([[    0,   133,   724,     9,   301,    16, 50264,     4,     2]])\n",
      "Attention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Creating the inputs for the model with the help of the tokenizer. \n",
    "input_ids = tokenizer(\"The goal of life is <mask>.\", add_special_tokens=True, return_tensors=\"pt\").input_ids\n",
    "attn_mask = tokenizer(\"The goal of life is <mask>.\", add_special_tokens=True, return_tensors=\"pt\").attention_mask\n",
    "\n",
    "print(\"Input_ids:\", input_ids)\n",
    "print(\"Attention_mask\", attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[6;30;42mPyTorch output:\u001b[0m MaskedLMOutput(loss=None, logits=tensor([[[60.7068, -4.2327, 43.1175,  ..., -0.4020,  0.3316, 24.4074],\n",
      "         [33.6284, -3.6199, 48.9813,  ...,  1.9244,  1.0682, 22.7686],\n",
      "         [35.7190, -3.4319, 45.7293,  ...,  0.1514,  2.1498, 24.3901],\n",
      "         ...,\n",
      "         [39.9738, -3.9358, 50.3689,  ...,  1.3725,  1.3659, 27.4736],\n",
      "         [58.6038, -5.4432, 63.5591,  ...,  1.6673,  1.9001, 34.7030],\n",
      "         [53.3719, -4.3540, 72.4312,  ...,  2.8634,  2.2205, 32.5310]]],\n",
      "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# Storing the pytorch model's output in pt_outputs variable.\n",
    "pt_outputs = model(input_ids, attn_mask)\n",
    "\n",
    "print('\\x1b[6;30;42m' + 'PyTorch output:' + '\\x1b[0m', pt_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aakash/anaconda3/envs/openvino/lib/python3.7/site-packages/transformers/modeling_utils.py:1760: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input_tensor.shape[chunk_dim] == tensor_shape for input_tensor in input_tensors\n"
     ]
    }
   ],
   "source": [
    "# Exporting from torch to onnx.\n",
    "torch.onnx.export(model,\n",
    "                 (input_ids, attn_mask),\n",
    "                 \"roberta-large.onnx\",\n",
    "                 input_names=[\"input_ids\", \"attn_mask\"],\n",
    "                 output_names=[\"outputs\"],\n",
    "                 opset_version=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/aakash/box_of_ai_tools/Natural_Language_Processing/Senitment_Analysis/Roberta large/roberta-large.onnx\n",
      "\t- Path for generated IR: \t/home/aakash/box_of_ai_tools/Natural_Language_Processing/Senitment_Analysis/Roberta large/.\n",
      "\t- IR output name: \troberta-large\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tFalse\n",
      "ONNX specific parameters:\n",
      "Model Optimizer version: \t2021.2.0-1877-176bdf51370-releases/2021/2\n",
      "[ WARNING ]  Convert data type of Parameter \"input_ids\" to int32\n",
      "[ WARNING ]  Convert data type of Parameter \"attn_mask\" to int32\n",
      "\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: /home/aakash/box_of_ai_tools/Natural_Language_Processing/Senitment_Analysis/Roberta large/./roberta-large.xml\n",
      "[ SUCCESS ] BIN file: /home/aakash/box_of_ai_tools/Natural_Language_Processing/Senitment_Analysis/Roberta large/./roberta-large.bin\n",
      "[ SUCCESS ] Total execution time: 134.99 seconds. \n",
      "[ SUCCESS ] Memory consumed: 4962 MB. \n"
     ]
    }
   ],
   "source": [
    "# Converting from onnx to openvino.\n",
    "!python3 /opt/intel/openvino_2021.2.200/deployment_tools/model_optimizer/mo.py --input_model roberta-large.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IECore\n",
    "ie = IECore()\n",
    "\n",
    "openvino_mbart = ie.read_network(model=\"roberta-large.xml\", weights=\"roberta-large.bin\")\n",
    "exec_mbart = ie.load_network(network=openvino_mbart, device_name=\"CPU\", num_requests=1)\n",
    "openvino_outputs = exec_mbart.infer(inputs={\"input_ids\": input_ids,\n",
    "                                            \"attn_mask\": attn_mask})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[6;30;42mOpenvino output:\u001b[0m {'outputs': array([[[60.707005  , -4.2329526 , 43.11875   , ..., -0.4020666 ,\n",
      "          0.33146667, 24.408428  ],\n",
      "        [33.62696   , -3.619597  , 48.98063   , ...,  1.9243897 ,\n",
      "          1.0682645 , 22.767698  ],\n",
      "        [35.715885  , -3.4314222 , 45.72687   , ...,  0.15133601,\n",
      "          2.1498716 , 24.388264  ],\n",
      "        ...,\n",
      "        [39.973934  , -3.9358125 , 50.369087  , ...,  1.3724074 ,\n",
      "          1.3660294 , 27.473736  ],\n",
      "        [58.603844  , -5.4432616 , 63.55898   , ...,  1.6671664 ,\n",
      "          1.9000208 , 34.703053  ],\n",
      "        [53.37203   , -4.354007  , 72.431335  , ...,  2.863402  ,\n",
      "          2.220527  , 32.531105  ]]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print('\\x1b[6;30;42m' + 'Openvino output:' + '\\x1b[0m', openvino_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino",
   "language": "python",
   "name": "openvino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
