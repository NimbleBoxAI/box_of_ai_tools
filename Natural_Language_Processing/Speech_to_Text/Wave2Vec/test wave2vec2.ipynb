{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Tokenizer, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561052a2cf934d32abbcc0be71c1e451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=291.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618365775de54cc58a0f54a4e8e1551b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=163.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c409de79207465db1b92c399827a247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=85.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d882412854846a3b24acd3611eff78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=843.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656b77acc4c7411385c01491152de932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=377667514.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " # load model and tokenizer\n",
    " tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    " model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219040,) 16000\n"
     ]
    }
   ],
   "source": [
    "speech, bitrate = sf.read(\"./sample1.flac\")\n",
    "print(speech.shape, bitrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "input_values = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 219040])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve logits\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# take argmax and decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = tokenizer.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"GOING ALONG SLUSHY COUNTRY ROADS AND SPEAKING TO DAMP AUDIENCES IN DRAUGHTY SCHOOL ROOMS DAY AFTER DAY FOR A FORTNIGHT HE'LL HAVE TO PUT IN AN APPEARANCE AT SOME PLACE OF WORSHIP ON SUNDAY MORNING AND HE CAN COME TO US IMMEDIATELY AFTERWARDS\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0, 21,  0,  0,  0,  8,  0,  0,  0, 10,\n",
       "          9, 21, 21,  4,  4,  7,  7,  0, 15,  0,  0,  8,  9,  9, 21, 21,  0,  4,\n",
       "          4,  0,  0,  0,  0, 12, 12,  0,  0,  0, 15, 15,  0,  0, 16,  0,  0, 12,\n",
       "          0, 11,  0,  0,  0,  0, 22,  0,  4,  4,  0,  0,  0,  0, 19,  0,  0,  8,\n",
       "         16, 16,  9,  9,  0,  6,  6,  0, 13,  0,  0, 22, 22,  4,  4,  0, 13, 13,\n",
       "          0,  0,  0,  0,  8,  8,  7,  0,  0,  0, 14,  0,  0, 12, 12,  4,  4,  0,\n",
       "          7,  9, 14, 14,  4,  4,  0, 12,  0, 23,  0,  5,  0,  7,  0, 26,  0,  0,\n",
       "          0, 10,  9, 21, 21,  4,  4,  6,  6,  8,  8,  4,  4,  0, 14,  0,  0,  0,\n",
       "          0,  0,  7, 17, 17,  0,  0, 23,  0,  0,  4,  0,  0,  0,  0,  0,  7, 16,\n",
       "         16,  0,  0, 14,  0, 10, 10,  0,  0,  5,  9,  9,  0,  0, 19,  0,  0,  0,\n",
       "          5,  5,  0,  0, 12, 12,  4,  4,  4,  0,  0, 10,  9,  0,  4,  4,  0,  0,\n",
       "         14,  0, 13,  0,  0,  0,  0,  0,  7, 16, 21, 11, 11,  0,  0,  6,  0,  0,\n",
       "          0, 22,  0,  4,  4,  0, 12, 12, 19, 11, 11,  8,  8,  0,  0,  8,  8, 15,\n",
       "         15,  0,  4,  0, 13, 13,  8,  0,  0,  0,  8, 17,  0,  0,  0, 12, 12,  4,\n",
       "          4,  4,  4,  0, 14,  0,  0,  0,  7,  7, 22,  0,  4,  4,  0,  0,  0,  7,\n",
       "         20,  0,  0,  6,  0,  5, 13,  4,  4, 14, 14,  0,  0,  7,  7, 22, 22,  4,\n",
       "          4,  0, 20,  0,  8, 13,  0,  4,  7,  4,  4, 20, 20,  0,  0,  8, 13, 13,\n",
       "          0,  6,  6,  0,  0,  0,  0,  0,  9,  9,  0,  0, 10,  0, 21, 11,  6,  6,\n",
       "          0,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 11,  5,  0,  0, 27, 15,  0,  0,\n",
       "         15,  4, 11, 11,  7,  0, 25,  5,  4,  4,  6,  8,  4,  4,  4, 23,  0,  0,\n",
       "         16,  0,  6,  0,  4,  4,  4, 10,  9,  4,  4,  4,  4,  7,  9,  4,  4,  7,\n",
       "         23,  0,  0, 23,  0,  0,  5,  0,  7,  0, 13, 13,  0,  0,  0,  7,  9,  9,\n",
       "          0, 19, 19,  5,  0,  4,  4,  4,  0,  7,  6,  4,  4,  0, 12, 12,  0,  0,\n",
       "          0,  8, 17, 17,  5,  5,  0,  0,  4,  4,  0,  0, 23, 15, 15,  0,  0,  7,\n",
       "          0,  0, 19,  5,  5,  0,  4,  4,  8, 20,  4,  4,  4,  4,  0, 18,  0,  0,\n",
       "          8,  0, 13,  0,  0,  0, 12, 11, 11,  0,  0, 10,  0,  0, 23,  0,  0,  4,\n",
       "          0,  0,  0,  0,  0,  0,  8,  9,  0,  0,  4,  4,  4,  4,  0, 12,  0,  0,\n",
       "          0, 16,  9,  9,  0,  0,  0, 14,  0,  0,  7, 22, 22,  4,  4,  0, 17,  0,\n",
       "          0,  8,  0, 13,  0,  9,  0,  0, 10,  9,  9, 21, 21,  4,  4,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  7,  9, 14,\n",
       "         14,  4,  4, 11,  0,  5,  0,  4,  4, 19,  0,  7,  9,  0,  4,  4,  0, 19,\n",
       "          0,  0,  8, 17,  0,  5,  4,  4,  6,  0,  8,  4,  4,  0,  0,  0, 16,  0,\n",
       "          0, 12,  0,  0,  4,  4,  4,  4, 10, 17,  0,  0,  0, 17,  0,  0,  5,  0,\n",
       "         14,  0, 10, 10,  0,  7,  6,  5,  5,  5,  0, 15, 15, 22, 22,  4,  4,  0,\n",
       "          0,  0,  0,  0,  7, 20,  0,  0,  0,  6,  0,  5, 13, 13,  0, 18,  0,  0,\n",
       "          7, 13, 14, 14, 12,  4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:288: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert attn_weights.size() == (\n",
      "/usr/local/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:327: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert attn_output.size() == (\n"
     ]
    }
   ],
   "source": [
    "# Exporting from torch to onnx produces some errors and they\n",
    "# are because of how the t5-small model is coded in the transformers\n",
    "# package and onnx cannot track the flow of python values and thats why\n",
    "# cannot generate a proper model graph but still generates one.  \n",
    "torch.onnx.export(model,\n",
    "                 (input_values),\n",
    "                 \"model.onnx\",\n",
    "                 input_names=[\"input_ids\"],\n",
    "                 output_names=[\"logits\"],\n",
    "                 opset_version=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\r\n",
      "Common parameters:\r\n",
      "\t- Path to the Input Model: \t/Users/yashbonde/Desktop/wrk/nbx/box_of_ai_tools/Natural_Language_Processing/Speech_to_Text/Wave2Vec/model.onnx\r\n",
      "\t- Path for generated IR: \t/Users/yashbonde/Desktop/wrk/nbx/box_of_ai_tools/Natural_Language_Processing/Speech_to_Text/Wave2Vec/.\r\n",
      "\t- IR output name: \tmodel\r\n",
      "\t- Log level: \tERROR\r\n",
      "\t- Batch: \tNot specified, inherited from the model\r\n",
      "\t- Input layers: \tNot specified, inherited from the model\r\n",
      "\t- Output layers: \tNot specified, inherited from the model\r\n",
      "\t- Input shapes: \tNot specified, inherited from the model\r\n",
      "\t- Mean values: \tNot specified\r\n",
      "\t- Scale values: \tNot specified\r\n",
      "\t- Scale factor: \tNot specified\r\n",
      "\t- Precision of IR: \tFP32\r\n",
      "\t- Enable fusing: \tTrue\r\n",
      "\t- Enable grouped convolutions fusing: \tTrue\r\n",
      "\t- Move mean values to preprocess section: \tNone\r\n",
      "\t- Reverse input channels: \tFalse\r\n",
      "ONNX specific parameters:\r\n",
      "Model Optimizer version: \t2021.2.0-1877-176bdf51370-releases/2021/2\r\n",
      "[ ERROR ]  \r\n",
      "Detected not satisfied dependencies:\r\n",
      "\tonnx: not installed, required: >= 1.1.2\r\n",
      "\ttest-generator: not installed, required: == 0.1.1\r\n",
      "\r\n",
      "Please install required versions of components or use install_prerequisites script\r\n",
      "/Users/yashbonde/Desktop/wrk/nbx/openvino/openvino_2021.2.185/deployment_tools/model_optimizer/install_prerequisites/install_prerequisites_onnx.sh\r\n",
      "Note that install_prerequisites scripts may install additional components.\r\n",
      "[ ERROR ]  check_requirements exit with return code 1\r\n"
     ]
    }
   ],
   "source": [
    "# Converting from onnx to openvino fails because of the above mentioned reason.  \n",
    "!python3 /path/to/openvino/openvino_2021.2.185/deployment_tools/model_optimizer/mo.py --input_model model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above error comes because of incorrect initialisation of variables, which can be fixed if you follow the instructions [here](https://github.com/NimbleBoxAI/hf2OpenVino). Once initialised correctly, run the instructions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "net = ie.read_network(\"./model.xml\", \"./model.bin\")\n",
    "exec_net = ie.load_network(network=net, device_name=\"CPU\", num_requests=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = exec_net.infer(inputs={\"input_values\": input_values})[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = [tokenizer.decode(x) for x in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
