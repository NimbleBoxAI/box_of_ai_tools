{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 23155393\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Returns a Linkenet model which is basically just torch.nn.Module\n",
    "fpn = smp.FPN(encoder_name=\"resnet34\",\n",
    "                       encoder_weights=\"imagenet\",\n",
    "                       activation=\"sigmoid\",\n",
    "                       in_channels=3)\n",
    "\n",
    "# preprocessing input\n",
    "preprocess = smp.encoders.get_preprocessing_fn('resnet34', pretrained='imagenet')\n",
    "params = sum(p.numel() for p in fpn.parameters())\n",
    "print(\"Parameters:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting torch to onnx\n",
    "\n",
    "# Onnx input \n",
    "\n",
    "x = torch.randn(1,3, 320, 320)\n",
    "torch_out = fpn(x)\n",
    "torch.onnx.export(fpn,\n",
    "                 x,\n",
    "                 \"fpn.onnx\",\n",
    "                 input_names=[\"input\"],\n",
    "                 output_names=[\"output\"],\n",
    "                 opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/aakash/box_of_ai_tools/Semantic_segmentation/FPN/fpn.onnx\n",
      "\t- Path for generated IR: \t/home/aakash/box_of_ai_tools/Semantic_segmentation/FPN/.\n",
      "\t- IR output name: \tfpn\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tFalse\n",
      "ONNX specific parameters:\n",
      "Model Optimizer version: \t2021.2.0-1877-176bdf51370-releases/2021/2\n",
      "\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: /home/aakash/box_of_ai_tools/Semantic_segmentation/FPN/./fpn.xml\n",
      "[ SUCCESS ] BIN file: /home/aakash/box_of_ai_tools/Semantic_segmentation/FPN/./fpn.bin\n",
      "[ SUCCESS ] Total execution time: 15.62 seconds. \n",
      "[ SUCCESS ] Memory consumed: 1062 MB. \n"
     ]
    }
   ],
   "source": [
    "#converting from onnx to openvino \n",
    "!python3 /opt/intel/openvino_2021.2.200/deployment_tools/model_optimizer/mo.py --input_model fpn.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IECore\n",
    "ie = IECore()\n",
    "\n",
    "# These files including fpn.bin, fpn.mapping, fpn.xml are\n",
    "# create after converting the onnx model to openvino through the above step\n",
    "openvino_fpn = ie.read_network(model=\"fpn.xml\", weights=\"fpn.bin\")\n",
    "exec_fpn = ie.load_network(network=openvino_fpn, device_name=\"CPU\", num_requests=1)\n",
    "openvino_out = exec_fpn.infer(inputs={\"input\": x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[6;30;42mTorch output:\u001b[0m [[[[0.10395543 0.08551674 0.07009269 ... 0.08466275 0.08908384\n",
      "    0.0937123 ]\n",
      "   [0.0854074  0.06752576 0.05317032 ... 0.10531915 0.10736913\n",
      "    0.10945418]\n",
      "   [0.06991055 0.05309994 0.04015706 ... 0.13029797 0.12887664\n",
      "    0.12746848]\n",
      "   ...\n",
      "   [0.20545308 0.22620896 0.24840611 ... 0.09234217 0.08514489\n",
      "    0.07845989]\n",
      "   [0.29497662 0.3110103  0.32751065 ... 0.11361311 0.10530783\n",
      "    0.09754264]\n",
      "   [0.40369308 0.41073096 0.41780555 ... 0.13903414 0.12957008\n",
      "    0.12065973]]]]\n",
      "\u001b[6;30;42mOnnx output:\u001b[0m [[[[0.02624548 0.02296202 0.02008086 ... 0.03038321 0.03751354\n",
      "    0.04623741]\n",
      "   [0.01909207 0.0165462  0.01433486 ... 0.02786471 0.03499186\n",
      "    0.04385973]\n",
      "   [0.01386063 0.01190119 0.01021589 ... 0.02554947 0.03263395\n",
      "    0.04159896]\n",
      "   ...\n",
      "   [0.02299815 0.02010209 0.01756415 ... 0.02474755 0.02769434\n",
      "    0.03098087]\n",
      "   [0.02260811 0.02019344 0.0180319  ... 0.02304409 0.0256618\n",
      "    0.0285682 ]\n",
      "   [0.02222452 0.02028519 0.01851187 ... 0.02145528 0.02377478\n",
      "    0.0263383 ]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aakash/anaconda3/envs/openvino/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print('\\x1b[6;30;42m' + 'Torch output:' + '\\x1b[0m', torch_out.detach().numpy())\n",
    "print('\\x1b[6;30;42m' + 'Onnx output:' + '\\x1b[0m', openvino_out[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
