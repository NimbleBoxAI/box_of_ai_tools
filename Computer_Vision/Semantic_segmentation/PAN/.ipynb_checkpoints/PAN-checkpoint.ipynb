{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 21475816\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Returns a Linkenet model which is basically just torch.nn.Module\n",
    "pan = smp.pan.model.PAN(encoder_name=\"resnet34\",\n",
    "                       encoder_weights=\"imagenet\",\n",
    "                       activation=\"sigmoid\",\n",
    "                       in_channels=3)\n",
    "\n",
    "# preprocessing input\n",
    "preprocess = smp.encoders.get_preprocessing_fn('resnet34', pretrained='imagenet')\n",
    "params = sum(p.numel() for p in pan.parameters())\n",
    "print(\"Parameters:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting torch to onnx\n",
    "\n",
    "# Onnx input \n",
    "\n",
    "x = torch.randn(2,3, 128, 128)\n",
    "torch_out = pan(x)\n",
    "torch.onnx.export(pan,\n",
    "                 x,\n",
    "                 \"pan.onnx\",\n",
    "                 input_names=[\"input\"],\n",
    "                 output_names=[\"output\"],\n",
    "                 opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/aakash/box_of_ai_tools/Semantic_segmentation/PAN/pan.onnx\n",
      "\t- Path for generated IR: \t/home/aakash/box_of_ai_tools/Semantic_segmentation/PAN/.\n",
      "\t- IR output name: \tpan\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tFalse\n",
      "ONNX specific parameters:\n",
      "Model Optimizer version: \t2021.2.0-1877-176bdf51370-releases/2021/2\n",
      "\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: /home/aakash/box_of_ai_tools/Semantic_segmentation/PAN/./pan.xml\n",
      "[ SUCCESS ] BIN file: /home/aakash/box_of_ai_tools/Semantic_segmentation/PAN/./pan.bin\n",
      "[ SUCCESS ] Total execution time: 15.22 seconds. \n",
      "[ SUCCESS ] Memory consumed: 1082 MB. \n"
     ]
    }
   ],
   "source": [
    "#converting from onnx to openvino \n",
    "!python3 /opt/intel/openvino_2021.2.200/deployment_tools/model_optimizer/mo.py --input_model pan.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IECore\n",
    "ie = IECore()\n",
    "\n",
    "# These files including pan.bin, pan.mapping, pan.xml are\n",
    "# create after converting the onnx model to openvino through the above step\n",
    "openvino_pan = ie.read_network(model=\"pan.xml\", weights=\"pan.bin\")\n",
    "exec_pan = ie.load_network(network=openvino_pan, device_name=\"CPU\", num_requests=1)\n",
    "openvino_out = exec_pan.infer(inputs={\"input\": x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[6;30;42mTorch output:\u001b[0m [[[[0.43092817 0.30854422 0.20820114 ... 0.18358259 0.21274322\n",
      "    0.2451452 ]\n",
      "   [0.5305932  0.38945615 0.2646918  ... 0.15158997 0.1732054\n",
      "    0.19718687]\n",
      "   [0.6278764  0.4769505  0.33011952 ... 0.12432365 0.13971159\n",
      "    0.15666354]\n",
      "   ...\n",
      "   [0.66548103 0.54779196 0.4245041  ... 0.16052847 0.19457799\n",
      "    0.23383829]\n",
      "   [0.67905825 0.5350995  0.38504502 ... 0.16264279 0.1919984\n",
      "    0.2252276 ]\n",
      "   [0.6923392  0.5223613  0.34704167 ... 0.16477953 0.18944497\n",
      "    0.21684417]]]\n",
      "\n",
      "\n",
      " [[[0.244274   0.19497882 0.1536095  ... 0.12246855 0.15552442\n",
      "    0.19551492]\n",
      "   [0.38328755 0.29324925 0.2169223  ... 0.11468107 0.13296925\n",
      "    0.15366781]\n",
      "   [0.5444209  0.41548586 0.2971684  ... 0.1073282  0.11324654\n",
      "    0.1194476 ]\n",
      "   ...\n",
      "   [0.6369233  0.5789023  0.5186171  ... 0.29305935 0.25227395\n",
      "    0.21543467]\n",
      "   [0.7050676  0.6365815  0.5620699  ... 0.31708944 0.26066735\n",
      "    0.2111799 ]\n",
      "   [0.76513875 0.6905832  0.60459125 ... 0.3421365  0.2692395\n",
      "    0.20698695]]]]\n",
      "\u001b[6;30;42mOnnx output:\u001b[0m [[[[0.27377692 0.29311407 0.3132279  ... 0.34035257 0.36890838\n",
      "    0.39841303]\n",
      "   [0.30725393 0.31696242 0.32683295 ... 0.3302445  0.35550046\n",
      "    0.38158742]\n",
      "   [0.34289172 0.3418129  0.34073576 ... 0.32029086 0.34231552\n",
      "    0.36504126]\n",
      "   ...\n",
      "   [0.44317722 0.4331933  0.4232633  ... 0.3633587  0.39070052\n",
      "    0.41874644]\n",
      "   [0.48649493 0.46205112 0.4377885  ... 0.34700766 0.3628373\n",
      "    0.37897   ]\n",
      "   [0.5300164  0.49116555 0.45242104 ... 0.3310099  0.33586589\n",
      "    0.34075686]]]\n",
      "\n",
      "\n",
      " [[[0.359979   0.35670552 0.35344538 ... 0.42157826 0.4510152\n",
      "    0.48079908]\n",
      "   [0.402545   0.3960752  0.38964158 ... 0.40094417 0.42117482\n",
      "    0.4416736 ]\n",
      "   [0.44663185 0.43683946 0.42709604 ... 0.38065535 0.39189935\n",
      "    0.40325916]\n",
      "   ...\n",
      "   [0.43039873 0.43535182 0.44031787 ... 0.3837898  0.38674816\n",
      "    0.38971493]\n",
      "   [0.4712653  0.47120044 0.4711356  ... 0.3977712  0.38417733\n",
      "    0.37076202]\n",
      "   [0.5125207  0.50734854 0.5021749  ... 0.4119214  0.38161293\n",
      "    0.352199  ]]]]\n"
     ]
    }
   ],
   "source": [
    "print('\\x1b[6;30;42m' + 'Torch output:' + '\\x1b[0m', torch_out.detach().numpy())\n",
    "print('\\x1b[6;30;42m' + 'Openvino output:' + '\\x1b[0m', openvino_out[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
